---
title: "Accessing the model outputs"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(randomForest)
library(raster)


```

Before starting, make sure the logistic regression models and their standard error predictions are in the same folder, called "lr_outs", and random forest ones are in a separate folder, called "rf_outs".

## Logistic regressions

First, get a list of the files and make sure that they are loaded in the correct (alphabetical) order.


```{r lr}

# plot all the linear regression outputs
# nex to their standard errors
# assumes they are loaded in alphabetically!
fls_lr <- list.files("C:/Users/thoval/Documents/Analyses/lr_outs/", full.names = T)
fls_lr

```


You can see from the output that the standard errors of each species come immediately after the model outputs, which we will use to plot them all later. To start with, let's just look at a single species, the common heath Ematurga atomaria.


```{r Ematurga_atomaria}

# get the files of the species of interest
EA <- fls_lr[grepl(pattern = 'atomaria', x = fls_lr)]

# The first file will be the predictions
load(EA[1])

# the second will be the standard errors
load(EA[2])

```


The probability distributions are stored in the "out" object, along with a bunch of other entries including the data it was fitted with. The standard errors in the "se_out" object, which is just a single raster layer.

```{r Ematurga_atomaria2, fig.height=5, fig.width=11}

par(mfrow = c(1,2))

plot(out$Predictions, main = paste(out$Species, "AUC = ", round(out$AUC, 2)))
points(x = out$Data$lon[out$Data$val == 1], out$Data$lat[out$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)

plot(se_out, main = paste(out$Species, "SE"))

  
```

As you can see, the model looks like it is highly certain of the standard errors. However, after discussing it with Susan, this is probably what you'd expect from the model, the uncertainty will be tied to very high uncertanty regions which will mask underlying variation in the predictions. This isn't helped by the colour scale automatically generated by R!

We can also get the summary of the model outputs, like last time. 

We're also going to store the logistic regression output for common heath as a separate object, to compare it directly to the random forest model later on.

```{r mod_summ}

summary(out$Model)

lr_out_EA <- out

```


As I mentioned above, the files are alphabetical so we can plot them in a for loop quite easily. The loop below plots the j'th object and the j + 1'th object next to each other, which because they were loaded in alphabetically means that you will have the predictions on the left and the standard error on the right. This takes a while because there are a lot of plots.

```{r plot_lr, fig.height=8, fig.width=10}


par(mfrow = c(2,2))

# for loop to go through

for(j in seq(1,length(fls_lr), by = 2)){
  load(fls_lr[j])
  load(fls_lr[j+1])
  
  plot(out$Predictions, main = paste(out$Species, "AUC", round(out$AUC,4)))
  points(x = out$Data$lon[out$Data$val == 1], out$Data$lat[out$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)
  
  plot(se_out, main = paste(out$Species, "SE"))
  
  
}


```


## Random forest

Now let's look at the random forest models. We'll start with Ematurga atomaria again, and then plot them all side-by-side. First look in folder "rf_outs/". 


```{r rf}

fls_rf <- list.files("C:/Users/thoval/Documents/Analyses/rf_outs/", full.names = T)
fls_rf


```

Extract the files for Ematurga atomaria.

```{r Ematurga_atomaria_rf}

# get the files of the species of interest
EA_rf <- fls_rf[grepl(pattern = 'atomaria', x = fls_rf)]

# The first file will be the predictions
load(EA_rf)

# still stored as the object 'out'
class(out$Model)


```


The probability distributions are still stored in the "out" object, along with the same other entries including the data it was fitted with. There are still no error predictions for the random forest plots.


```{r Ematurga_atomaria_rf2, fig.height=5, fig.width=11}

par(mfrow = c(1,1))

plot(out$Predictions, main = paste(out$Species, "AUC = ", round(out$AUC, 2), class(out$Model)))
points(x = out$Data$lon[out$Data$val == 1], out$Data$lat[out$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)
  
```

Let's compare the random forest and logistic regression outputs for the common heath.


```{r compare, fig.height=5, fig.width=11}


par(mfrow = c(1,2))

plot(out$Predictions, main = paste(out$Species, "AUC = ", round(out$AUC, 2), class(out$Model)))
points(x = out$Data$lon[out$Data$val == 1], out$Data$lat[out$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)

plot(lr_out_EA$Predictions, main = paste(lr_out_EA$Species, "AUC = ", round(lr_out_EA$AUC, 2), class(lr_out_EA$Model)[1]))
points(x = lr_out_EA$Data$lon[lr_out_EA$Data$val == 1], lr_out_EA$Data$lat[lr_out_EA$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)

par(mfrow = c(1,1))


```

They're pretty similar (I think), but might break down for other other species.

Going to store this as an object to compare to GAMs below.

```{r}

rf_out_EA <- out


```


With random forests you can extract the variable importance plots. The values are stored in the model object, but the easiest way of plotting it is to have the randomForest package loaded (which we did above).


```{r var_imp, fig.height=8, fig.width=7}

out$Model$importance

varImpPlot(out$Model, pch = 20, main = "Variable importance")


```

Now we can plot all the random forest outputs using a for loop. This will probably throw an error for Lycia zonaria, in which case just delete the file, something went wrong with it during the modelling and I didn't spot it until I had already sent it to you. When you delete it, don't forget to run the list of files again (included in the chunk below).


```{r rf_all, fig.height=8, fig.width=10}

fls_rf <- list.files("rf_outs/", full.names = T)
fls_rf

par(mfrow = c(2,2))

for(i in fls_rf){
  load(i)
  plot(out$Predictions, main = paste(out$Species, "AUC", round(out$AUC,4)))
  points(x = out$Data$lon[out$Data$val == 1], out$Data$lat[out$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)
}



```

## GAMs time

Get the GAM outputs.



```{r gam}

fls_gam <- list.files("C:/Users/thoval/Documents/Analyses/gam_outs/", full.names = T)
fls_gam


```

Extract the GAM files for Ematurga atomaria.

```{r Ematurga_atomaria_gam}

# get the files of the species of interest
EA_gam <- fls_gam[grepl(pattern = 'Ematurga atomaria', x = fls_gam)]

# The first file will be the predictions
load(EA_gam[1])

# The second file will be the SEs
load(EA_gam[2])

# still stored as the object 'out'
class(out$Model)[1]

gam_out_EA <- out

```

Plot the GAM predictions and standard errors for Ematurga atomaria.

```{r plot_gam, fig.height=5, fig.width=11}

par(mfrow = c(1,2))
plot(out$Predictions, main = paste(out$Species, "AUC = ", round(out$AUC, 2)))
points(x = out$Data$lon[out$Data$val == 1], out$Data$lat[out$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)

plot(se_out, main = paste(out$Species, "SE"))
par(mfrow = c(1,1))

```

Now let's compare logistc regression, random forests and GAMs for Ematurga atomaria


```{r comp_lr_rf_gam, fig.height=3, fig.width=12}

par(mfrow = c(1,3))

# lr plot
plot(lr_out_EA$Predictions, main = paste(lr_out_EA$Species, class(lr_out_EA$Model)[1], round(lr_out_EA$AUC, 3)))
  points(x = lr_out_EA$Data$lon[lr_out_EA$Data$val == 1], lr_out_EA$Data$lat[lr_out_EA$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)
plot(rf_out_EA$Predictions, main = paste(rf_out_EA$Species, class(rf_out_EA$Model)[1], round(rf_out_EA$AUC, 3)))
  points(x = rf_out_EA$Data$lon[out$Data$val == 1], rf_out_EA$Data$lat[rf_out_EA$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)
plot(gam_out_EA$Predictions, main = paste(gam_out_EA$Species, class(gam_out_EA$Model)[1], round(gam_out_EA$AUC, 3)))
  points(x = gam_out_EA$Data$lon[gam_out_EA$Data$val == 1], gam_out_EA$Data$lat[gam_out_EA$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)


```


Plot all the GAM models and their standard errors next to each other. Same principle as for the logistic regressions. There are fewer species for the GAM models than the random forests and the logistic regression because it doesn't cope very well with few data points (as soon as there are too many covariates it throws an error because of the way it calculates the basis functions). I will try to figure out a way of reducing the number of covariates in a meaningful and non-biased way asap. But, if we are trying to use different models for the same species then is it fair to fit some of them with reduced covariates and not others? Almost certainly not, but reducing the number of covariates will likely benefit all models, so need to come up with a way of deciding covariates by **species**, not **model**.


```{r gam_pred_se, fig.height=8, fig.width=10}


par(mfrow = c(2,2))

# for loop to go through

for(j in seq(1,length(fls_gam), by = 2)){
  load(fls_gam[j])
  load(fls_gam[j+1])
  
  plot(out$Predictions, main = paste(out$Species, "AUC", round(out$AUC,4)))
  points(x = out$Data$lon[out$Data$val == 1], out$Data$lat[out$Data$val == 1],
         cex = 0.6, col = "red", pch = 20)
  
  plot(se_out, main = paste(out$Species, "SE"))
  
  
}


```


## Calculating error

We want to use a high-throughput approach which means that we can't target the environmental/habitat variables for each species. This means going with very broad conditions, which in turn probably means that our SDMs for each species aren't going to be the best quality. While it is possible that we could increase model fit by, for e.g., increasing the absences for low-abundance insects, this will introduce some biases to the models. Rob Boyd said that he didn't really believe the results in the paper by Barbet-Massin *et al.* (2012; Meth. ecol. evol. - even though it has > 1000 citations...) and so advocates matching the presence and pseudoabsences, rather than increasing pseudo abs.

So, while this will be computationally intensive, I think that following Rob's approach for getting SDMs, by running different models and creating a weighted probability of presence output, might be the best way to go. This makes extracting error a bit tricky of course. Rob also needs to investigate model error and he is going to go down the permutation route - predicting from the model on subsets of the presence-absence data to get a range of probabilities for each model and then combining the different prediction probabilities. He plans on doing this for each model because the SEs from a logistic regression/GAM won't be the same as any errors (e.g. OOB error) from random forests/maxent and therefore aren't really comparable. By running each model on multiple samples of the data (i.e. bootstrapping), we would be able to get a range of prediction probability scores for each grid cell. We would just predict the probability of occurence from each of models run on subsets of the data. 





I think that's everything, let me know if there's anything you want to talk through.
